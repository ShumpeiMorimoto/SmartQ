from dotenv import load_dotenv
load_dotenv()

from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
from openai import OpenAI
import os
import logging


# Hypothetical free plan token limit for demonstration
FREE_PLAN_LIMIT = 1_000_000
tokens_used = 0


logging.basicConfig(
    level=logging.INFO,  # INFOä»¥ä¸Šã‚’å‡ºåŠ›
    format="%(asctime)s [%(levelname)s] %(message)s",
)

app = FastAPI()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

current_quiz = {"question": None, "answer": None}

app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/")
async def root():
    return FileResponse("static/index.html")

# ä»¥é™ /quiz, /answer, /health ã¯ãã®ã¾ã¾
# çœç•¥



class AnswerRequest(BaseModel):
    answer: str

@app.get("/health")
async def health_check():
    """OpenAI APIã¨é€šä¿¡ã§ãã‚‹ã‹ç°¡å˜ãªå•ã„åˆã‚ã›ã§ç¢ºèª"""
    try:
        # ç°¡å˜ãªChatCompletionå‘¼ã³å‡ºã—ï¼ˆç©ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§pingçš„ã«ä½¿ã†ï¼‰
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": "ã“ã‚“ã«ã¡ã¯"}],
            temperature=0
        )
        return {"status": "ok", "message": response.choices[0].message.content}
    except Exception as e:
        return {"status": "error", "detail": str(e)}

@app.get("/quiz")
async def get_quiz():
    global tokens_used
    logging.info("æ–°ã—ã„ã‚¯ã‚¤ã‚ºãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ä¿¡ã—ã¾ã—ãŸ")
    
    # ...
    try:
        response = client.chat.completions.create(
            model="gpt-5.2",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯4æŠã‚¯ã‚¤ã‚ºä½œæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
                {
                    "role": "user", "content":
                    "æ—¥æœ¬èªã§è¤‡é›‘ãª4æŠã‚¯ã‚¤ã‚ºã‚’1å•ä½œã£ã¦ãã ã•ã„ã€‚"
                    "ã€Œå•é¡Œã€ã€Œé¸æŠè‚¢(4ã¤)ã€ã€Œæ­£è§£ã€ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
                    "å¿…ãšæ¬¡ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
                    "\nå•é¡Œ: å•é¡Œæ–‡\né¸æŠè‚¢: é¸æŠè‚¢1, é¸æŠè‚¢2, é¸æŠè‚¢3, é¸æŠè‚¢4\næ­£è§£: é¸æŠè‚¢1"
                }
            ],
            # verbosity="medium",
            temperature=0.7,
        )
        content = response.choices[0].message.content
        
        # --- Token Tracking ---
        request_tokens = response.usage.total_tokens
        tokens_used += request_tokens
        remaining_tokens = FREE_PLAN_LIMIT - tokens_used
        logging.info(f"Token usage for this request: {request_tokens}")
        logging.info(f"Total tokens used so far: {tokens_used}")
        logging.info(f"Remaining tokens on free plan (simulated): {remaining_tokens}")
        # --------------------

        lines = content.split("\n")
        question = None
        choices = []
        answer = None

        for line in lines:
            if line.startswith("å•é¡Œ:"):
                question = line.replace("å•é¡Œ:", "").strip()
            elif line.startswith("é¸æŠè‚¢:"):
                choices = [c.strip() for c in line.replace("é¸æŠè‚¢:", "").split(",")]
            elif line.startswith("æ­£è§£:"):
                answer = line.replace("æ­£è§£:", "").strip()

        current_quiz["question"] = question
        current_quiz["answer"] = answer

        logging.info(f"ç”Ÿæˆã•ã‚ŒãŸå•é¡Œ: {question}")

        return {
            "question": question,
            "choices": choices
        }

    except Exception as e:
        return {"error": str(e)}


@app.post("/answer")
async def check_answer(req: AnswerRequest):
    if current_quiz["answer"] is None:
        return {"error": "ã‚¯ã‚¤ã‚ºãŒã¾ã å‡ºé¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"}

    user_answer = req.answer.strip().lower()
    correct_answer = current_quiz["answer"].lower()

    if user_answer == correct_answer:
        result = "æ­£è§£ã§ã™ï¼ğŸ‰"
    else:
        result = f"ä¸æ­£è§£ã§ã™ã€‚æ­£ã—ã„ç­”ãˆã¯ã€Œ{current_quiz['answer']}ã€ã§ã™ã€‚"

    return {"result": result}
